{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from skimage import io, transform\n",
    "from skimage.color import rgba2rgb\n",
    "from collections import OrderedDict\n",
    "from kymatio import Scattering2D\n",
    "import kymatio.datasets as scattering_datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "TRAIN = 'train'\n",
    "VAL = 'val'\n",
    "PRED = 'pred'\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "print ('Using GPU:', use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images and labels, preprocessing, and convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get painting labels\n",
    "labels = {}\n",
    "\n",
    "with open('Project1-Raphael/label.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter='.')\n",
    "    for row in csv_reader:\n",
    "        labels[row[0]] = row[1].strip()\n",
    "\n",
    "\n",
    "# load images of painting and construct into dataframe\n",
    "image_extensions = ['.TIF', '.tif', '.tiff', '.jpg']\n",
    "data_set = []\n",
    "\n",
    "for file in os.listdir('Project1-Raphael'):\n",
    "    extension = os.path.splitext(file)[1]\n",
    "    \n",
    "    if extension in image_extensions:\n",
    "        \n",
    "        filename = os.path.splitext(file)[0]\n",
    "        image = io.imread(os.path.join('Project1-Raphael', file))\n",
    "        if image.shape[2] == 4:\n",
    "            image = rgba2rgb(image)\n",
    "        image = np.array(image)\n",
    "        if image.max() <= 1:\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "        if image.max() > 255:\n",
    "            image = (image / 255).astype(np.uint8)\n",
    "        else:\n",
    "            image_id = filename.split(' ')[0].replace('.', '')\n",
    "            label = labels[image_id]\n",
    "\n",
    "            if label == 'Raphael':\n",
    "                data_set.append({'Image': image, 'Disputed': 0, 'Raphael': 1, 'ID':image_id})\n",
    "            elif label == 'Not Raphael':\n",
    "                data_set.append({'Image': image, 'Disputed': 0, 'Raphael': 0, 'ID':image_id})\n",
    "            else:\n",
    "                data_set.append({'Image': image, 'Disputed': 1, 'Raphael': -1, 'ID':image_id})\n",
    "\n",
    "df = pd.DataFrame(data_set)\n",
    "training_df = df[df['Disputed'] == 0]\n",
    "validation_df = df[df['Disputed'] == 0]\n",
    "prediction_df = df[df['Disputed'] == 1]\n",
    "dataframes = {'train': training_df, 'val': training_df, 'pred':prediction_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaphaelPaintingsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (DataFrame): A dataframe containing painting image and painted by Raphael label.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.image = df['Image'].values\n",
    "        self.raphael = df['Raphael'].values\n",
    "        self.data_id = df['ID'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raphael)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        image = Image.fromarray(self.image[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.raphael[idx], dtype=torch.int64)\n",
    "        data_id = self.data_id[idx]\n",
    "        \n",
    "        sample = {'image': image, 'label': label, 'id': data_id}\n",
    "        return sample\n",
    "    \n",
    "\n",
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        transforms.Resize(512),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ]),\n",
    "    VAL: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ]),\n",
    "    PRED: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "}\n",
    "\n",
    "datasets = {\n",
    "    x: RaphaelPaintingsDataset(dataframes[x], data_transforms[x])\n",
    "    for x in [TRAIN, VAL, PRED]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(datasets[x], batch_size=12, shuffle=True, num_workers=2)\n",
    "    for x in [TRAIN, VAL, PRED]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define train and validate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, scattering=None):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    \n",
    "    for samples in train_loader:\n",
    "        images, labels = samples['image'], samples['label']\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if scattering:\n",
    "            output = model(scattering(images))\n",
    "        else:\n",
    "            output = model.forward(images)\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        train_accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "    return train_loss, train_accuracy\n",
    "        \n",
    "def validate(model, device, validate_loader, scattering=None):\n",
    "    model.eval()\n",
    "    validate_loss = 0\n",
    "    validate_accuracy = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for samples in validate_loader:\n",
    "            images, labels = samples['image'], samples['label']\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            if scattering:\n",
    "                output = model(scattering(images))\n",
    "            else:\n",
    "                output = model.forward(images)\n",
    "            \n",
    "            validate_loss += criterion(output, labels).item()\n",
    "            \n",
    "            ps = torch.exp(output)\n",
    "            equality = (labels.data == ps.max(dim=1)[1])\n",
    "            validate_accuracy += equality.type(torch.FloatTensor).mean()\n",
    "            \n",
    "    return validate_loss, validate_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invariant scattering networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100..  Train (Loss: 262.5260 Accuracy: 0.812 )  Validate (Loss: 14.533 Accuracy: 0.71 )\n",
      "Epoch: 20/100..  Train (Loss: 6.0882 Accuracy: 0.875 )  Validate (Loss: 11.019 Accuracy: 0.85 )\n",
      "Epoch: 30/100..  Train (Loss: 43.9822 Accuracy: 0.750 )  Validate (Loss: 19.900 Accuracy: 0.90 )\n",
      "Epoch: 40/100..  Train (Loss: 65.9122 Accuracy: 0.833 )  Validate (Loss: 2.420 Accuracy: 0.90 )\n",
      "Epoch: 50/100..  Train (Loss: 49.8260 Accuracy: 0.792 )  Validate (Loss: 46.965 Accuracy: 0.92 )\n",
      "Epoch: 60/100..  Train (Loss: 220.2227 Accuracy: 0.771 )  Validate (Loss: 9.674 Accuracy: 0.90 )\n",
      "Epoch: 70/100..  Train (Loss: 26.9802 Accuracy: 0.812 )  Validate (Loss: 59.389 Accuracy: 0.75 )\n",
      "Epoch: 80/100..  Train (Loss: 25.5899 Accuracy: 0.875 )  Validate (Loss: 4.710 Accuracy: 0.96 )\n",
      "Epoch: 90/100..  Train (Loss: 41.3156 Accuracy: 0.917 )  Validate (Loss: 32.981 Accuracy: 0.83 )\n",
      "Epoch: 100/100..  Train (Loss: 99.7101 Accuracy: 0.750 )  Validate (Loss: 29.084 Accuracy: 0.85 )\n"
     ]
    }
   ],
   "source": [
    "scattering = Scattering2D(J=2, shape=(224, 224))\n",
    "K = 81*3\n",
    "if use_cuda:\n",
    "    scattering = scattering.cuda()\n",
    "\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(-1,*self.shape)\n",
    "\n",
    "\n",
    "ScatterMLP = nn.Sequential(View(K, 56, 56),\n",
    "                           nn.BatchNorm2d(K),\n",
    "                           View(K*56*56),\n",
    "                           nn.Linear(K*56*56, 512),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(512, 256),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(256, 2),\n",
    "                           nn.LogSoftmax(dim=1))\n",
    "ScatterMLP.to(device)\n",
    "\n",
    "for m in ScatterMLP.modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "        m.weight.data.normal_(0, 2./math.sqrt(m.in_features))\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "\n",
    "# model training\n",
    "epochs = 100\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(ScatterMLP.parameters(), lr=0.001)\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    train_loss, train_accuracy = train(ScatterMLP, device, dataloaders[TRAIN], optimizer, scattering)\n",
    "    validate_loss, validate_accuracy = validate(ScatterMLP, device, dataloaders[VAL], scattering) \n",
    "    \n",
    "    if (e+1) % 10 == 0:\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Train (Loss: {:.4f}\".format(train_loss/len(dataloaders[TRAIN])),\n",
    "              \"Accuracy: {:.3f}\".format(train_accuracy/len(dataloaders[TRAIN])),\n",
    "              \")  Validate (Loss: {:.3f}\".format(validate_loss/len(dataloaders[VAL])),\n",
    "              \"Accuracy: {:.2f}\".format(validate_accuracy/len(dataloaders[VAL])),\n",
    "              \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning using pretrained vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20..  Train (Loss: 2.6310 Accuracy: 0.417 )  Validate (Loss: 3.175 Accuracy: 0.58 )\n",
      "Epoch: 2/20..  Train (Loss: 3.3421 Accuracy: 0.604 )  Validate (Loss: 2.445 Accuracy: 0.60 )\n",
      "Epoch: 3/20..  Train (Loss: 1.6424 Accuracy: 0.708 )  Validate (Loss: 0.145 Accuracy: 0.90 )\n",
      "Epoch: 4/20..  Train (Loss: 0.3526 Accuracy: 0.833 )  Validate (Loss: 2.019 Accuracy: 0.62 )\n",
      "Epoch: 5/20..  Train (Loss: 1.5856 Accuracy: 0.729 )  Validate (Loss: 0.324 Accuracy: 0.83 )\n",
      "Epoch: 6/20..  Train (Loss: 0.2674 Accuracy: 0.854 )  Validate (Loss: 0.180 Accuracy: 0.94 )\n",
      "Epoch: 7/20..  Train (Loss: 0.1174 Accuracy: 0.958 )  Validate (Loss: 0.334 Accuracy: 0.92 )\n",
      "Epoch: 8/20..  Train (Loss: 0.4625 Accuracy: 0.792 )  Validate (Loss: 0.279 Accuracy: 0.96 )\n",
      "Epoch: 9/20..  Train (Loss: 0.3809 Accuracy: 0.854 )  Validate (Loss: 0.065 Accuracy: 0.96 )\n",
      "Epoch: 10/20..  Train (Loss: 0.1934 Accuracy: 0.938 )  Validate (Loss: 0.019 Accuracy: 1.00 )\n",
      "Epoch: 11/20..  Train (Loss: 0.0529 Accuracy: 1.000 )  Validate (Loss: 0.030 Accuracy: 1.00 )\n",
      "Epoch: 12/20..  Train (Loss: 0.7168 Accuracy: 0.792 )  Validate (Loss: 0.008 Accuracy: 1.00 )\n",
      "Epoch: 13/20..  Train (Loss: 0.4334 Accuracy: 0.896 )  Validate (Loss: 0.022 Accuracy: 1.00 )\n",
      "Epoch: 14/20..  Train (Loss: 0.4816 Accuracy: 0.896 )  Validate (Loss: 0.018 Accuracy: 1.00 )\n",
      "Epoch: 15/20..  Train (Loss: 0.3853 Accuracy: 0.896 )  Validate (Loss: 0.014 Accuracy: 1.00 )\n",
      "Epoch: 16/20..  Train (Loss: 0.0344 Accuracy: 1.000 )  Validate (Loss: 0.012 Accuracy: 1.00 )\n",
      "Epoch: 17/20..  Train (Loss: 0.2890 Accuracy: 0.833 )  Validate (Loss: 0.020 Accuracy: 1.00 )\n",
      "Epoch: 18/20..  Train (Loss: 0.1312 Accuracy: 0.958 )  Validate (Loss: 0.028 Accuracy: 1.00 )\n",
      "Epoch: 19/20..  Train (Loss: 0.1186 Accuracy: 0.938 )  Validate (Loss: 0.013 Accuracy: 1.00 )\n",
      "Epoch: 20/20..  Train (Loss: 0.0932 Accuracy: 1.000 )  Validate (Loss: 0.011 Accuracy: 1.00 )\n"
     ]
    }
   ],
   "source": [
    "# model definition\n",
    "vgg19 = models.vgg19(pretrained=True)\n",
    "\n",
    "for param in vgg19.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 1024)),\n",
    "                                        ('relu1', nn.ReLU()),\n",
    "                                        ('fc2', nn.Linear(1024,2)),\n",
    "                                        ('output', nn.LogSoftmax(dim=1))\n",
    "                                       ]))\n",
    "\n",
    "vgg19.classifier = classifier\n",
    "vgg19.to(device)\n",
    "\n",
    "\n",
    "# model training\n",
    "epochs = 20\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(vgg19.classifier.parameters(), lr=0.001)\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    train_loss, train_accuracy = train(vgg19, device, dataloaders[TRAIN], optimizer)\n",
    "    validate_loss, validate_accuracy = validate(vgg19, device, dataloaders[VAL]) \n",
    "            \n",
    "    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "          \"Train (Loss: {:.4f}\".format(train_loss/len(dataloaders[TRAIN])),\n",
    "          \"Accuracy: {:.3f}\".format(train_accuracy/len(dataloaders[TRAIN])),\n",
    "          \")  Validate (Loss: {:.3f}\".format(validate_loss/len(dataloaders[VAL])),\n",
    "          \"Accuracy: {:.2f}\".format(validate_accuracy/len(dataloaders[VAL])),\n",
    "          \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for ScatterNet and vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction by scattering MLP model:\n",
      " {'1': 0, '10': 1, '20': 1, '23': 1, '25': 0, '26': 1, '7': 1}\n",
      "Prediction by vgg16 model:\n",
      " {'1': 0, '10': 0, '20': 0, '23': 0, '25': 0, '26': 0, '7': 0}\n"
     ]
    }
   ],
   "source": [
    "def predict(model, device, predict_loader, scattering=None):\n",
    "    model.eval()\n",
    "    predict = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for samples in predict_loader:\n",
    "            images = samples['image']\n",
    "            images = images.to(device)\n",
    "            \n",
    "            if scattering:\n",
    "                output = model(scattering(images))\n",
    "            else:\n",
    "                output = model.forward(images)\n",
    "            \n",
    "            ps = torch.exp(output).detach().cpu().numpy().astype(np.uint8)\n",
    "            data_id = samples['id']\n",
    "            \n",
    "            for i in range(len(data_id)):\n",
    "                predict[data_id[i]] = ps[i][0]\n",
    "    \n",
    "    predict = dict(sorted(predict.items()))\n",
    "    return predict\n",
    "\n",
    "\n",
    "scatter_net_predict = predict(ScatterMLP, device, dataloaders[PRED], scattering)\n",
    "print (\"Prediction by scattering MLP model:\\n\", scatter_net_predict)\n",
    "\n",
    "vgg19_predict = predict(vgg19, device, dataloaders[PRED])\n",
    "print (\"Prediction by vgg16 model:\\n\", vgg19_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 1\n",
    "\n",
    "Comparing the first two feature extraction approches, the deep learning model perform much better than the scattering net model. Using transfoer learning on pretrained vgg19, we see a fast and study decrease in both traing and validation accuracy, acheaving 100% in a few epoch. Note the validation accuracy is higher than traing accuracy because with random crop and random flip, the traing set is much harder than the validation and prediction set. This is data augmentation to improve model training. In this part, we can say the deep learning model is better and should give a more accurate prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    image_set = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical unsupervised learning: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca_image_set = pca.fit_transform(image_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional supervised learning: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
